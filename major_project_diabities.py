# -*- coding: utf-8 -*-
"""major project diabities.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iz4b5RJBLpEJ1NaQvMH-_kP4cCBVhMXJ

Importing the Dependencies
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score

"""Data Collection and Analysis

PIMA Diabetes Dataset
"""

# loading the diabetes dataset to a pandas DataFrame
diabetes_dataset = pd.read_csv('G:\major_MDP\multiple-disease-prediction-streamlit-app-main\dataset\diabetes.csv')

# printing the first 5 rows of the dataset
diabetes_dataset.head()

# number of rows and Columns in this dataset
diabetes_dataset.shape

# getting the statistical measures of the data
diabetes_dataset.describe()

diabetes_dataset['Outcome'].value_counts()

"""0 --> Non-Diabetic

1 --> Diabetic
"""

diabetes_dataset.groupby('Outcome').mean()

# separating the data and labels


print(X)

print(Y)

"""Train Test Split"""

X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, stratify=Y, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

"""Training the Model"""

classifier = svm.SVC(kernel='linear')

#training the support vector Machine Classifier
classifier.fit(X_train, Y_train)

"""Model Evaluation"""

# accuracy score on the training data
X_train_prediction = classifier.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)

if isinstance(Y_train, pd.Series):
  Y_train = Y_train.to_numpy()

"""Accuracy Score"""

print('Accuracy score of the training data : ', training_data_accuracy)

# accuracy score on the test data
X_test_prediction = classifier.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)

print('Accuracy score of the test data : ', test_data_accuracy)

# prompt: train aDecision
# Tree
# Classifier system and give its accuracy like this "accuracy_score(X_train_prediction, Y_train)"

from sklearn.tree import DecisionTreeClassifier

dt_classifier = DecisionTreeClassifier()
dt_classifier.fit(X_train, Y_train)
dt_train_prediction = dt_classifier.predict(X_train)
dt_training_data_accuracy = accuracy_score(dt_train_prediction, Y_train)
print('Accuracy score of the training data : ', dt_training_data_accuracy)

# prompt: give decision tree acuuracy on testing data

dt_test_prediction = dt_classifier.predict(X_test)
dt_test_data_accuracy = accuracy_score(dt_test_prediction, Y_test)
print('Accuracy score of the testing data : ', dt_test_data_accuracy)

# prompt: train a Na√Øve
# Bias
# Classifier system and gi
# ves its accuracy like this "accuracy_score(X_train_prediction, Y_train)"

from sklearn.naive_bayes import GaussianNB

nb_classifier = GaussianNB()
nb_classifier.fit(X_train, Y_train)
nb_train_prediction = nb_classifier.predict(X_train)
nb_training_data_accuracy = accuracy_score(nb_train_prediction, Y_train)
print('Accuracy score of the training data : ', nb_training_data_accuracy)

# prompt: give naive bayes accuracy test on testing data

nb_test_prediction = nb_classifier.predict(X_test)
nb_test_data_accuracy = accuracy_score(nb_test_prediction, Y_test)
print('Accuracy score of the test data : ', nb_test_data_accuracy)

# prompt: train a random forest classifier  and give its accuracy on training data

from sklearn.ensemble import RandomForestClassifier

rf_classifier = RandomForestClassifier(n_estimators=100)
rf_classifier.fit(X_train, Y_train)

rf_train_prediction = rf_classifier.predict(X_train)
rf_training_data_accuracy = accuracy_score(rf_train_prediction, Y_train)

print('Accuracy score of the training data : ', rf_training_data_accuracy)

# prompt: give accuracy of testing data for random forest classifier

rf_test_prediction = rf_classifier.predict(X_test)
rf_test_data_accuracy = accuracy_score(rf_test_prediction, Y_test)
print('Accuracy score of the test data : ', rf_test_data_accuracy)

# prompt: train a Logistic Regression model and give its accuracy on training model

from sklearn.linear_model import LogisticRegression

lr_classifier = LogisticRegression()
lr_classifier.fit(X_train, Y_train)

lr_train_prediction = lr_classifier.predict(X_train)
lr_training_data_accuracy = accuracy_score(lr_train_prediction, Y_train)

print('Accuracy score of the training data : ', lr_training_data_accuracy)

# prompt: give accuracy of logistic regression model on testing data

lr_test_prediction = lr_classifier.predict(X_test)
lr_test_data_accuracy = accuracy_score(lr_test_prediction, Y_test)
print('Accuracy score of the test data : ', lr_test_data_accuracy)

"""Making a Predictive System"""

input_data = (5,166,72,19,175,25.8,0.587,51)

# changing the input_data to numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the array as we are predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = classifier.predict(input_data_reshaped)
print(prediction)

if (prediction[0] == 0):
  print('The person is not diabetic')
else:
  print('The person is diabetic')

"""Saving the trained model"""

import pickle

filename = 'diabetes_model.sav'
pickle.dump(classifier, open(filename, 'wb'))

# loading the saved model
loaded_model = pickle.load(open('diabetes_model.sav', 'rb'))

input_data = (5,166,72,19,175,25.8,0.587,51)

# changing the input_data to numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the array as we are predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = loaded_model.predict(input_data_reshaped)
print(prediction)

if (prediction[0] == 0):
  print('The person is not diabetic')
else:
  print('The person is diabetic')

for column in X.columns:
  print(column)

# prompt: check the age group of patient using  plt figure , something like this "sns.set_style('darkgrid')
# plt.figure(figsize=(25,10))
# patients['Age'].value_counts().plot.bar(color='darkviolet')"

import seaborn as sns
import matplotlib.pyplot as plt

sns.set_style('darkgrid')
plt.figure(figsize=(25,10))
diabetes_dataset['Age'].value_counts().plot.bar(color='darkviolet')
plt.show()

# prompt: make a correlation between the features using a heatmap:

plt.figure(figsize=(10,5))
sns.heatmap(diabetes_dataset.corr(), annot=True)
plt.show()

# prompt: create a distribution plot for each feature who has diabities and showcase it in bar chart using different colors

# Create a list of features
features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']

# Create a figure and axes
fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(20, 20))

# Loop through each feature and create a distribution plot
for i, feature in enumerate(features):
  # Select data for diabetic and non-diabetic patients
  diabetic_data = diabetes_dataset[diabetes_dataset['Outcome'] == 1][feature]
  non_diabetic_data = diabetes_dataset[diabetes_dataset['Outcome'] == 0][feature]

  # Create a distribution plot for diabetic patients
  sns.distplot(diabetic_data, hist=False, label="Diabetic", ax=axes[i // 2, i % 2], color='red')

  # Create a distribution plot for non-diabetic patients
  sns.distplot(non_diabetic_data, hist=False, label="Non-Diabetic", ax=axes[i // 2, i % 2], color='green')

  # Add title and legend
  axes[i // 2, i % 2].set_title(feature)
  axes[i // 2, i % 2].legend()

# Show the plot
plt.show()

# prompt: can you create a model performance matrix for every trained model and their accuracy on testing data and showcase it in bar chart

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Create a list of model names and their corresponding test data accuracy scores
model_names = ['SVM', 'Decision Tree', 'Naive Bayes', 'Random Forest', 'Logistic Regression']
accuracy_scores = [test_data_accuracy, dt_test_data_accuracy, nb_test_data_accuracy, rf_test_data_accuracy, lr_test_data_accuracy]

# Create a DataFrame
df = pd.DataFrame({'Model Name': model_names, 'Test Accuracy': accuracy_scores})

# Create a bar chart
sns.barplot(x='Model Name', y='Test Accuracy', data=df)
plt.xlabel('Model Name')
plt.ylabel('Test Accuracy')
plt.xticks(rotation=45)
plt.show()